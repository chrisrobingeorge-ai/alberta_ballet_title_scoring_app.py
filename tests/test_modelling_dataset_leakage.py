"""
End-to-end leakage test for the modelling dataset.

This test serves as a final guardrail before training, ensuring that:
1. The target column is not present in the feature set X.
2. No forbidden current-run ticket columns appear as features.

This test runs on the actual modelling_dataset.csv file generated by
scripts/build_modelling_dataset.py, providing an end-to-end validation.
"""

import os
import pytest
import pandas as pd

# Reuse the forbidden pattern definitions from test_no_leakage_in_dataset.py
from tests.test_no_leakage_in_dataset import (
    FORBIDDEN_PATTERNS,
    ALLOWED_COLUMNS,
    is_forbidden_column,
)


# Target column name used in the modelling dataset
TARGET_COL = "target_ticket_median"

# Columns that should not be used as features (identifiers and target)
NON_FEATURE_COLS = {"title", "canonical_title", "show_title", "show_title_id", TARGET_COL}


def load_modelling_dataset(path: str = "data/modelling_dataset.csv") -> pd.DataFrame:
    """Load the modelling dataset from CSV."""
    if not os.path.exists(path):
        raise FileNotFoundError(f"Modelling dataset not found at {path}")
    return pd.read_csv(path)


def split_X_y(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.Series]:
    """
    Split the modelling dataset into features (X) and target (y).
    
    Args:
        df: The full modelling dataset DataFrame.
        
    Returns:
        Tuple of (X, y) where X contains features and y contains the target.
    """
    # Determine feature columns (exclude non-feature columns)
    feature_cols = [c for c in df.columns if c not in NON_FEATURE_COLS]
    
    X = df[feature_cols].copy()
    
    # Extract target if present
    if TARGET_COL in df.columns:
        y = df[TARGET_COL].copy()
    else:
        y = pd.Series(dtype=float)
    
    return X, y


class TestModellingDatasetLeakage:
    """End-to-end leakage tests for the modelling dataset."""
    
    @pytest.fixture
    def dataset(self):
        """Load the modelling dataset or skip if not available."""
        dataset_path = "data/modelling_dataset.csv"
        if not os.path.exists(dataset_path):
            pytest.skip(f"Modelling dataset not found at {dataset_path}")
        return load_modelling_dataset(dataset_path)
    
    @pytest.fixture
    def X_y(self, dataset):
        """Split dataset into features and target."""
        return split_X_y(dataset)
    
    def test_target_not_in_features(self, X_y):
        """
        Ensure the target column is not present in the feature set X.
        
        This is critical to prevent target leakage during model training.
        """
        X, y = X_y
        
        assert TARGET_COL not in X.columns, (
            f"TARGET LEAKAGE: Target column '{TARGET_COL}' found in features X.\n"
            f"This must be excluded to prevent leakage during training.\n"
            f"X columns: {list(X.columns)}"
        )
    
    def test_no_forbidden_patterns_in_features(self, X_y):
        """
        Ensure no columns matching forbidden patterns appear in features X.
        
        Forbidden patterns include current-run ticket columns like
        "Single Tickets - Calgary" that would leak future information.
        """
        X, y = X_y
        
        forbidden_found = []
        for col in X.columns:
            if is_forbidden_column(col):
                forbidden_found.append(col)
        
        assert len(forbidden_found) == 0, (
            f"DATA LEAKAGE: Found forbidden current-run ticket columns in features:\n"
            f"  {forbidden_found}\n\n"
            f"These columns must NOT be used as predictors because they contain\n"
            f"current-run information that would not be available at forecast time.\n\n"
            f"Forbidden patterns: {FORBIDDEN_PATTERNS}"
        )
    
    def test_feature_count_reasonable(self, X_y):
        """
        Sanity check that we have a reasonable number of features.
        
        This catches potential issues where features are accidentally dropped
        or the dataset is malformed.
        """
        X, y = X_y
        
        assert len(X.columns) >= 5, (
            f"Too few features ({len(X.columns)}). Expected at least 5 features.\n"
            f"This may indicate a problem with the dataset build process.\n"
            f"Found columns: {list(X.columns)}"
        )
    
    def test_has_samples(self, X_y):
        """
        Sanity check that the dataset has rows.
        """
        X, y = X_y
        
        assert len(X) > 0, "Dataset has no rows. Cannot train without data."
    
    def test_X_and_y_aligned(self, X_y):
        """
        Verify X and y have the same number of rows.
        """
        X, y = X_y
        
        assert len(X) == len(y), (
            f"X and y have different lengths. X: {len(X)}, y: {len(y)}"
        )


# Additional standalone tests (for running without fixtures)
def test_modelling_dataset_no_target_in_features():
    """
    Standalone test: Ensure target column is not in the modelling dataset features.
    
    This test loads the modelling dataset directly and verifies that the target
    column is properly excluded from the feature set X.
    """
    dataset_path = "data/modelling_dataset.csv"
    
    if not os.path.exists(dataset_path):
        pytest.skip(f"Modelling dataset not found at {dataset_path}")
    
    df = load_modelling_dataset(dataset_path)
    X, y = split_X_y(df)
    
    assert TARGET_COL not in X.columns, (
        f"TARGET LEAKAGE: Target column '{TARGET_COL}' found in features X."
    )


def test_modelling_dataset_no_forbidden_columns():
    """
    Standalone test: Ensure no forbidden patterns appear in modelling dataset features.
    
    This test loads the modelling dataset directly and verifies that no current-run
    ticket columns (like "Single Tickets - Calgary") are present in the feature set.
    """
    dataset_path = "data/modelling_dataset.csv"
    
    if not os.path.exists(dataset_path):
        pytest.skip(f"Modelling dataset not found at {dataset_path}")
    
    df = load_modelling_dataset(dataset_path)
    X, y = split_X_y(df)
    
    forbidden_found = []
    for col in X.columns:
        if is_forbidden_column(col):
            forbidden_found.append(col)
    
    assert len(forbidden_found) == 0, (
        f"DATA LEAKAGE: Found forbidden columns in features:\n"
        f"  {forbidden_found}\n"
        f"These columns must not be used as predictors."
    )
